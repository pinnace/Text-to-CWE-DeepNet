{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook contains training code for the base model + extra security vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18151,
     "status": "ok",
     "timestamp": 1584283215106,
     "user": {
      "displayName": "Luke S",
      "photoUrl": "",
      "userId": "14962309687492295189"
     },
     "user_tz": -60
    },
    "id": "zBeMbWQBr13G",
    "outputId": "366620e1-1f73-4416-accf-c9e7b7658b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'transformers' already exists and is not an empty directory.\n",
      "Processing /data/notebooks/transformers\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (1.18.1)\n",
      "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (0.5.2)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (1.12.22)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (3.0.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (2.22.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (4.42.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (2020.2.20)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (0.1.85)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.5.1) (0.0.38)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.22 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.5.1) (1.15.22)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.5.1) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.5.1) (0.9.5)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.5.1) (1.25.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.5.1) (0.14.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.5.1) (1.14.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.5.1) (7.1.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.22->boto3->transformers==2.5.1) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.22->boto3->transformers==2.5.1) (0.15.2)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-2.5.1-py3-none-any.whl size=528611 sha256=fa05b4197415c1fdd51ac1b4aa90ae7372e76434a4beb5bdfc389c4f08a49b2a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-cs7p5sv5/wheels/5c/1c/47/7aca7c86ce98d3f7beb792bd7f926ef4d3cc45abd4f8daaa44\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 2.5.1\n",
      "    Uninstalling transformers-2.5.1:\n",
      "      Successfully uninstalled transformers-2.5.1\n",
      "Successfully installed transformers-2.5.1\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/huggingface/transformers\n",
    "!cd transformers && pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23566,
     "status": "ok",
     "timestamp": 1584283241291,
     "user": {
      "displayName": "Luke S",
      "photoUrl": "",
      "userId": "14962309687492295189"
     },
     "user_tz": -60
    },
    "id": "Ex_WffFWr687",
    "outputId": "0d22e2d8-1fca-4be1-af0f-7c2ac2127088"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15093,
     "status": "ok",
     "timestamp": 1584283257337,
     "user": {
      "displayName": "Luke S",
      "photoUrl": "",
      "userId": "14962309687492295189"
     },
     "user_tz": -60
    },
    "id": "s2NKPhhZsBt-",
    "outputId": "50bb3f03-02ef-461d-e14b-2dcb3e9d1e28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-SXM2-16GB\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# If there's a GPU available...\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_rbIV1AmsGTH"
   },
   "outputs": [],
   "source": [
    "data_dir = \"../datasets/TrainingV2/Train_test_validation/\"\n",
    "\n",
    "train_df = pd.read_csv(data_dir + \"train_cwe_nlp.csv\")\n",
    "validation_df = pd.read_csv(data_dir + \"validation_cwe_nlp.csv\")\n",
    "test_df = pd.read_csv(data_dir + \"test_cwe_nlp.csv\")\n",
    "underrep_df = pd.read_csv(data_dir + \"underrep_cwe_nlp.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67047\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1755,
     "status": "ok",
     "timestamp": 1584233539337,
     "user": {
      "displayName": "Lukas Stephan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioBWVaLUZnXCnDOZorMWKEyF2wML6Ssv5myxIf=s64",
      "userId": "03481974434335764588"
     },
     "user_tz": -60
    },
    "id": "-6IG9Yn0syAS",
    "outputId": "5edb23b8-6a4d-4dac-b0c2-4ad0450b630c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377\n",
      "348\n",
      "344\n",
      "Unique: 377\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_df['CWE-ID'].unique()\n",
    "validation_labels = validation_df['CWE-ID'].unique()\n",
    "test_labels = test_df['CWE-ID'].unique()\n",
    "merged_labels = np.concatenate((train_labels, validation_labels, test_labels))\n",
    "merged_labels = np.unique(merged_labels)\n",
    "print(len(train_labels))\n",
    "print(len(validation_labels))\n",
    "print(len(test_labels))\n",
    "print(\"Unique: {}\".format(len(merged_labels)))\n",
    "#print(np.logical_and( (train_labels==validation_labels).all(), (validation_labels==test_labels).all() ))\n",
    "#print(np.sort(merged_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 561,
     "status": "ok",
     "timestamp": 1584233541489,
     "user": {
      "displayName": "Lukas Stephan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioBWVaLUZnXCnDOZorMWKEyF2wML6Ssv5myxIf=s64",
      "userId": "03481974434335764588"
     },
     "user_tz": -60
    },
    "id": "TKLSJ8AGsn_T",
    "outputId": "b6046325-e600-49f0-cf15-3050461ae702"
   },
   "outputs": [],
   "source": [
    "lookup_table = dict(zip(list(merged_labels), range(0, len(merged_labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HczosksPtZXU"
   },
   "outputs": [],
   "source": [
    "train_df['CWE-ID'] = train_df['CWE-ID'].apply(lambda x:lookup_table[x])\n",
    "validation_df['CWE-ID'] = validation_df['CWE-ID'].apply(lambda x:lookup_table[x])\n",
    "test_df['CWE-ID'] = test_df['CWE-ID'].apply(lambda x:lookup_table[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AnFxSWhSjC5I"
   },
   "outputs": [],
   "source": [
    "# Configuration Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mXuqaKgdihzQ"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 4\n",
    "NUM_LABELS = len(lookup_table.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "5f8ae24b584f42eba9590e163a92d13d",
      "5243245110c342a0a118aa8a3a596d9a",
      "b737b456003540bfbfe10b6c465ec22e",
      "3344529ff90f4266af2aaf0c5566c0dd",
      "646ffdb86a37478c92c20e5401ccec46",
      "4017e4f4d45a4b319f731e9db1c24b7e",
      "d1c5232757d54bcb9cd347d8fc53b857",
      "52607b7d432648a9b688cfce5059bf0e"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4854,
     "status": "ok",
     "timestamp": 1584233553939,
     "user": {
      "displayName": "Lukas Stephan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioBWVaLUZnXCnDOZorMWKEyF2wML6Ssv5myxIf=s64",
      "userId": "03481974434335764588"
     },
     "user_tz": -60
    },
    "id": "C1y4le9duPjO",
    "outputId": "7e738c19-bcf5-46b1-910a-f91158ae6247"
   },
   "outputs": [],
   "source": [
    "MODELS = (BertForSequenceClassification,       BertTokenizer,       'bert-base-uncased')\n",
    "model_class, tokenizer_class, pretrained_weights = MODELS\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra vocabulary taken from the dataset and the following:\n",
    "# https://nvlpubs.nist.gov/nistpubs/ir/2013/NIST.IR.7298r2.pdf\n",
    "# https://www.sans.org/security-resources/glossary-of-terms/\n",
    "# https://www.owasp.org/images/1/19/OTGv4.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('../datasets/vocab/extra_vocab.json', 'r') as infile:\n",
    "    extra_vocab = json.load(infile)\n",
    "extra_tokens = extra_vocab[\"phrases\"] #extra_vocab[\"words\"] + \n",
    "tokenizer.add_tokens(extra_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ClorVgmjKA_"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_tokens(tokenizer, dataframe):\n",
    "  return dataframe['Description'].apply(lambda desc: \n",
    "                              tokenizer.encode(\n",
    "                                  desc, \n",
    "                                  add_special_tokens=True, \n",
    "                                  max_length=MAX_LEN, \n",
    "                                  pad_to_max_length=True\n",
    "                                  #return_tensors = 'pt'\n",
    "                                  )\n",
    "                              ).to_list()\n",
    "\n",
    "def get_attention_masks(input_ids):\n",
    "  attention_masks = []\n",
    "  for sent in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    attention_masks.append(att_mask)\n",
    "  return attention_masks\n",
    "\n",
    "\n",
    "train_input_tokens = get_tokens(tokenizer, train_df)\n",
    "validation_input_tokens = get_tokens(tokenizer, validation_df)\n",
    "test_input_tokens = get_tokens(tokenizer, test_df)\n",
    "\n",
    "train_masks = get_attention_masks(train_input_tokens)\n",
    "validation_masks = get_attention_masks(validation_input_tokens)\n",
    "test_masks = get_attention_masks(test_input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  The Spotfire Library component of TIBCO Software Inc.'s TIBCO Spotfire Analytics Platform for AWS Marketplace, and TIBCO Spotfire Server contains a vulnerability that might theoretically fail to restrict users with read-only access from modifying files stored in the Spotfire Library, only when the Spotfire Library is configured to use external storage. Affected releases are TIBCO Software Inc.'s TIBCO Spotfire Analytics Platform for AWS Marketplace versions up to and including 10.0.0, and TIBCO Spotfire Server versions up to and including 7.10.1; 7.11.0; 7.11.1; 7.12.0; 7.13.0; 7.14.0; 10.0.0.\n",
      "Tokenized:  ['the', 'spot', '##fire', 'library', 'component', 'of', 'ti', '##bc', '##o', 'software', 'inc', '.', \"'\", 's', 'ti', '##bc', '##o', 'spot', '##fire', 'analytics', 'platform', 'for', 'aw', '##s', 'marketplace', ',', 'and', 'ti', '##bc', '##o', 'spot', '##fire', 'server', 'contains', 'a', 'vulnerability', 'that', 'might', 'theoretically', 'fail', 'to', 'restrict', 'users', 'with', 'read', '-', 'only', 'access', 'from', 'modifying', 'files', 'stored', 'in', 'the', 'spot', '##fire', 'library', ',', 'only', 'when', 'the', 'spot', '##fire', 'library', 'is', 'configured', 'to', 'use', 'external', 'storage', '.', 'affected', 'releases', 'are', 'ti', '##bc', '##o', 'software', 'inc', '.', \"'\", 's', 'ti', '##bc', '##o', 'spot', '##fire', 'analytics', 'platform', 'for', 'aw', '##s', 'marketplace', 'versions', 'up', 'to', 'and', 'including', '10', '.', '0', '.', '0', ',', 'and', 'ti', '##bc', '##o', 'spot', '##fire', 'server', 'versions', 'up', 'to', 'and', 'including', '7', '.', '10', '.', '1', ';', '7', '.', '11', '.', '0', ';', '7', '.', '11', '.', '1', ';', '7', '.', '12', '.', '0', ';', '7', '.', '13', '.', '0', ';', '7', '.', '14', '.', '0', ';', '10', '.', '0', '.', '0', '.']\n",
      "Token IDs:  [1996, 3962, 10273, 3075, 6922, 1997, 14841, 9818, 2080, 4007, 4297, 1012, 1005, 1055, 14841, 9818, 2080, 3962, 10273, 25095, 4132, 2005, 22091, 2015, 18086, 1010, 1998, 14841, 9818, 2080, 3962, 10273, 8241, 3397, 1037, 18130, 2008, 2453, 22634, 8246, 2000, 21573, 5198, 2007, 3191, 1011, 2069, 3229, 2013, 29226, 6764, 8250, 1999, 1996, 3962, 10273, 3075, 1010, 2069, 2043, 1996, 3962, 10273, 3075, 2003, 26928, 2000, 2224, 6327, 5527, 1012, 5360, 7085, 2024, 14841, 9818, 2080, 4007, 4297, 1012, 1005, 1055, 14841, 9818, 2080, 3962, 10273, 25095, 4132, 2005, 22091, 2015, 18086, 4617, 2039, 2000, 1998, 2164, 2184, 1012, 1014, 1012, 1014, 1010, 1998, 14841, 9818, 2080, 3962, 10273, 8241, 4617, 2039, 2000, 1998, 2164, 1021, 1012, 2184, 1012, 1015, 1025, 1021, 1012, 2340, 1012, 1014, 1025, 1021, 1012, 2340, 1012, 1015, 1025, 1021, 1012, 2260, 1012, 1014, 1025, 1021, 1012, 2410, 1012, 1014, 1025, 1021, 1012, 2403, 1012, 1014, 1025, 2184, 1012, 1014, 1012, 1014, 1012]\n"
     ]
    }
   ],
   "source": [
    "print(' Original: ', train_df['Description'][0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(train_df['Description'][0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_df['Description'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zstDUMX_r9W5"
   },
   "outputs": [],
   "source": [
    "train_labels = train_df['CWE-ID'].values\n",
    "validation_labels = validation_df['CWE-ID'].values\n",
    "test_labels = test_df['CWE-ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBpnbhwXlCli"
   },
   "outputs": [],
   "source": [
    "# Model expects PyTorch tensors, not numpy arrays\n",
    "\n",
    "train_inputs = torch.tensor(train_input_tokens)\n",
    "validation_inputs = torch.tensor(validation_input_tokens)\n",
    "test_inputs = torch.tensor(test_input_tokens)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "test_masks = torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0rmlWeZkzkX"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# `BATCH_SIZE` specified elsewhere\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# 16 or 32. Either must be run on 16GB GPU, will crash runtime on anything less\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Create the DataLoader for our test set.\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "96f287cd332d437999a35f0acecbb815",
      "89421b3102464922837c72b24cb2a440",
      "55bc28d75021466d9e71aada1854668f",
      "03ea662ba605432a92dc26d0a28ff1ab",
      "3eaba4150a884a9faf441d94eb3cb30e",
      "ac4a4698a28c4be7976deb72bd505af8",
      "97950f4dcab84e00b5d7c86ed55175fe",
      "57da120472f3496e89904cb1a01da3e4",
      "105715a634d94e45b41960c494a330b1",
      "ad9cc6363b534e31a46dff19fe865fae",
      "210d481d407642bea4bb15ca693f4780",
      "bd11b11a7b56476e8a4dbf462ecb4b8d",
      "8c3bfc17779b491aa624c9a46d4d8c4e",
      "a5ad8695c94d4f08b7f190bf7c6d2385",
      "3bc72c0f4bc24ebb8c1f78b98e4e229a",
      "fc862b9e9f3d4c53a7e3357b0527b113"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 52668,
     "status": "ok",
     "timestamp": 1584233834973,
     "user": {
      "displayName": "Lukas Stephan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioBWVaLUZnXCnDOZorMWKEyF2wML6Ssv5myxIf=s64",
      "userId": "03481974434335764588"
     },
     "user_tz": -60
    },
    "id": "Aw8wiIEelkpF",
    "outputId": "e039a80b-61e9-4e0b-c644-4ab5cc126d66"
   },
   "outputs": [],
   "source": [
    "model = model_class.from_pretrained(\n",
    "    pretrained_weights, # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = NUM_LABELS, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30614, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Must resize the embedding layer after adding new vocabulary\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7tTYj01Sl3kN"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1606,
     "status": "error",
     "timestamp": 1584233882389,
     "user": {
      "displayName": "Lukas Stephan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GioBWVaLUZnXCnDOZorMWKEyF2wML6Ssv5myxIf=s64",
      "userId": "03481974434335764588"
     },
     "user_tz": -60
    },
    "id": "Ay70ECo6mBx9",
    "outputId": "bd79fe0c-210f-421c-fd97-94ee1a27b738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:1334: UserWarning: This overload of add_ is deprecated:\n",
      "add_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "add_(Tensor other, Number alpha)\n",
      "/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:1550: UserWarning: This overload of addcmul_ is deprecated:\n",
      "addcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "addcmul_(Tensor tensor1, Tensor tensor2, Number value)\n",
      "/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:1480: UserWarning: This overload of addcdiv_ is deprecated:\n",
      "addcdiv_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "addcdiv_(Tensor tensor1, Tensor tensor2, Number value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    40  of  4,191.    Elapsed: 0:00:20.\n",
      "  Batch    80  of  4,191.    Elapsed: 0:00:40.\n",
      "  Batch   120  of  4,191.    Elapsed: 0:01:00.\n",
      "  Batch   160  of  4,191.    Elapsed: 0:01:20.\n",
      "  Batch   200  of  4,191.    Elapsed: 0:01:40.\n",
      "  Batch   240  of  4,191.    Elapsed: 0:02:00.\n",
      "  Batch   280  of  4,191.    Elapsed: 0:02:20.\n",
      "  Batch   320  of  4,191.    Elapsed: 0:02:40.\n",
      "  Batch   360  of  4,191.    Elapsed: 0:03:00.\n",
      "  Batch   400  of  4,191.    Elapsed: 0:03:21.\n",
      "  Batch   440  of  4,191.    Elapsed: 0:03:41.\n",
      "  Batch   480  of  4,191.    Elapsed: 0:04:01.\n",
      "  Batch   520  of  4,191.    Elapsed: 0:04:21.\n",
      "  Batch   560  of  4,191.    Elapsed: 0:04:41.\n",
      "  Batch   600  of  4,191.    Elapsed: 0:05:01.\n",
      "  Batch   640  of  4,191.    Elapsed: 0:05:22.\n",
      "  Batch   680  of  4,191.    Elapsed: 0:05:42.\n",
      "  Batch   720  of  4,191.    Elapsed: 0:06:02.\n",
      "  Batch   760  of  4,191.    Elapsed: 0:06:22.\n",
      "  Batch   800  of  4,191.    Elapsed: 0:06:42.\n",
      "  Batch   840  of  4,191.    Elapsed: 0:07:03.\n",
      "  Batch   880  of  4,191.    Elapsed: 0:07:23.\n",
      "  Batch   920  of  4,191.    Elapsed: 0:07:43.\n",
      "  Batch   960  of  4,191.    Elapsed: 0:08:03.\n",
      "  Batch 1,000  of  4,191.    Elapsed: 0:08:23.\n",
      "  Batch 1,040  of  4,191.    Elapsed: 0:08:43.\n",
      "  Batch 1,080  of  4,191.    Elapsed: 0:09:04.\n",
      "  Batch 1,120  of  4,191.    Elapsed: 0:09:24.\n",
      "  Batch 1,160  of  4,191.    Elapsed: 0:09:44.\n",
      "  Batch 1,200  of  4,191.    Elapsed: 0:10:04.\n",
      "  Batch 1,240  of  4,191.    Elapsed: 0:10:24.\n",
      "  Batch 1,280  of  4,191.    Elapsed: 0:10:45.\n",
      "  Batch 1,320  of  4,191.    Elapsed: 0:11:05.\n",
      "  Batch 1,360  of  4,191.    Elapsed: 0:11:25.\n",
      "  Batch 1,400  of  4,191.    Elapsed: 0:11:45.\n",
      "  Batch 1,440  of  4,191.    Elapsed: 0:12:05.\n",
      "  Batch 1,480  of  4,191.    Elapsed: 0:12:26.\n",
      "  Batch 1,520  of  4,191.    Elapsed: 0:12:46.\n",
      "  Batch 1,560  of  4,191.    Elapsed: 0:13:06.\n",
      "  Batch 1,600  of  4,191.    Elapsed: 0:13:26.\n",
      "  Batch 1,640  of  4,191.    Elapsed: 0:13:46.\n",
      "  Batch 1,680  of  4,191.    Elapsed: 0:14:07.\n",
      "  Batch 1,720  of  4,191.    Elapsed: 0:14:27.\n",
      "  Batch 1,760  of  4,191.    Elapsed: 0:14:47.\n",
      "  Batch 1,800  of  4,191.    Elapsed: 0:15:07.\n",
      "  Batch 1,840  of  4,191.    Elapsed: 0:15:27.\n",
      "  Batch 1,880  of  4,191.    Elapsed: 0:15:48.\n",
      "  Batch 1,920  of  4,191.    Elapsed: 0:16:08.\n",
      "  Batch 1,960  of  4,191.    Elapsed: 0:16:28.\n",
      "  Batch 2,000  of  4,191.    Elapsed: 0:16:48.\n",
      "  Batch 2,040  of  4,191.    Elapsed: 0:17:08.\n",
      "  Batch 2,080  of  4,191.    Elapsed: 0:17:29.\n",
      "  Batch 2,120  of  4,191.    Elapsed: 0:17:49.\n",
      "  Batch 2,160  of  4,191.    Elapsed: 0:18:09.\n",
      "  Batch 2,200  of  4,191.    Elapsed: 0:18:29.\n",
      "  Batch 2,240  of  4,191.    Elapsed: 0:18:49.\n",
      "  Batch 2,280  of  4,191.    Elapsed: 0:19:10.\n",
      "  Batch 2,320  of  4,191.    Elapsed: 0:19:30.\n",
      "  Batch 2,360  of  4,191.    Elapsed: 0:19:50.\n",
      "  Batch 2,400  of  4,191.    Elapsed: 0:20:10.\n",
      "  Batch 2,440  of  4,191.    Elapsed: 0:20:30.\n",
      "  Batch 2,480  of  4,191.    Elapsed: 0:20:51.\n",
      "  Batch 2,520  of  4,191.    Elapsed: 0:21:11.\n",
      "  Batch 2,560  of  4,191.    Elapsed: 0:21:31.\n",
      "  Batch 2,600  of  4,191.    Elapsed: 0:21:51.\n",
      "  Batch 2,640  of  4,191.    Elapsed: 0:22:11.\n",
      "  Batch 2,680  of  4,191.    Elapsed: 0:22:32.\n",
      "  Batch 2,720  of  4,191.    Elapsed: 0:22:52.\n",
      "  Batch 2,760  of  4,191.    Elapsed: 0:23:12.\n",
      "  Batch 2,800  of  4,191.    Elapsed: 0:23:32.\n",
      "  Batch 2,840  of  4,191.    Elapsed: 0:23:52.\n",
      "  Batch 2,880  of  4,191.    Elapsed: 0:24:13.\n",
      "  Batch 2,920  of  4,191.    Elapsed: 0:24:33.\n",
      "  Batch 2,960  of  4,191.    Elapsed: 0:24:53.\n",
      "  Batch 3,000  of  4,191.    Elapsed: 0:25:13.\n",
      "  Batch 3,040  of  4,191.    Elapsed: 0:25:34.\n",
      "  Batch 3,080  of  4,191.    Elapsed: 0:25:54.\n",
      "  Batch 3,120  of  4,191.    Elapsed: 0:26:14.\n",
      "  Batch 3,160  of  4,191.    Elapsed: 0:26:34.\n",
      "  Batch 3,200  of  4,191.    Elapsed: 0:26:54.\n",
      "  Batch 3,240  of  4,191.    Elapsed: 0:27:15.\n",
      "  Batch 3,280  of  4,191.    Elapsed: 0:27:35.\n",
      "  Batch 3,320  of  4,191.    Elapsed: 0:27:55.\n",
      "  Batch 3,360  of  4,191.    Elapsed: 0:28:15.\n",
      "  Batch 3,400  of  4,191.    Elapsed: 0:28:35.\n",
      "  Batch 3,440  of  4,191.    Elapsed: 0:28:56.\n",
      "  Batch 3,480  of  4,191.    Elapsed: 0:29:16.\n",
      "  Batch 3,520  of  4,191.    Elapsed: 0:29:36.\n",
      "  Batch 3,560  of  4,191.    Elapsed: 0:29:56.\n",
      "  Batch 3,600  of  4,191.    Elapsed: 0:30:16.\n",
      "  Batch 3,640  of  4,191.    Elapsed: 0:30:36.\n",
      "  Batch 3,680  of  4,191.    Elapsed: 0:30:57.\n",
      "  Batch 3,720  of  4,191.    Elapsed: 0:31:17.\n",
      "  Batch 3,760  of  4,191.    Elapsed: 0:31:37.\n",
      "  Batch 3,800  of  4,191.    Elapsed: 0:31:57.\n",
      "  Batch 3,840  of  4,191.    Elapsed: 0:32:17.\n",
      "  Batch 3,880  of  4,191.    Elapsed: 0:32:38.\n",
      "  Batch 3,920  of  4,191.    Elapsed: 0:32:58.\n",
      "  Batch 3,960  of  4,191.    Elapsed: 0:33:18.\n",
      "  Batch 4,000  of  4,191.    Elapsed: 0:33:38.\n",
      "  Batch 4,040  of  4,191.    Elapsed: 0:33:59.\n",
      "  Batch 4,080  of  4,191.    Elapsed: 0:34:19.\n",
      "  Batch 4,120  of  4,191.    Elapsed: 0:34:39.\n",
      "  Batch 4,160  of  4,191.    Elapsed: 0:34:59.\n",
      "\n",
      "  Average training loss: 1.91\n",
      "  Training epoch took: 0:35:15\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.64\n",
      "  Validation took: 0:02:23\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  4,191.    Elapsed: 0:00:20.\n",
      "  Batch    80  of  4,191.    Elapsed: 0:00:40.\n",
      "  Batch   120  of  4,191.    Elapsed: 0:01:01.\n",
      "  Batch   160  of  4,191.    Elapsed: 0:01:21.\n",
      "  Batch   200  of  4,191.    Elapsed: 0:01:41.\n",
      "  Batch   240  of  4,191.    Elapsed: 0:02:01.\n",
      "  Batch   280  of  4,191.    Elapsed: 0:02:21.\n",
      "  Batch   320  of  4,191.    Elapsed: 0:02:42.\n",
      "  Batch   360  of  4,191.    Elapsed: 0:03:02.\n",
      "  Batch   400  of  4,191.    Elapsed: 0:03:22.\n",
      "  Batch   440  of  4,191.    Elapsed: 0:03:42.\n",
      "  Batch   480  of  4,191.    Elapsed: 0:04:02.\n",
      "  Batch   520  of  4,191.    Elapsed: 0:04:23.\n",
      "  Batch   560  of  4,191.    Elapsed: 0:04:43.\n",
      "  Batch   600  of  4,191.    Elapsed: 0:05:03.\n",
      "  Batch   640  of  4,191.    Elapsed: 0:05:23.\n",
      "  Batch   680  of  4,191.    Elapsed: 0:05:43.\n",
      "  Batch   720  of  4,191.    Elapsed: 0:06:04.\n",
      "  Batch   760  of  4,191.    Elapsed: 0:06:24.\n",
      "  Batch   800  of  4,191.    Elapsed: 0:06:44.\n",
      "  Batch   840  of  4,191.    Elapsed: 0:07:04.\n",
      "  Batch   880  of  4,191.    Elapsed: 0:07:25.\n",
      "  Batch   920  of  4,191.    Elapsed: 0:07:45.\n",
      "  Batch   960  of  4,191.    Elapsed: 0:08:05.\n",
      "  Batch 1,000  of  4,191.    Elapsed: 0:08:25.\n",
      "  Batch 1,040  of  4,191.    Elapsed: 0:08:45.\n",
      "  Batch 1,080  of  4,191.    Elapsed: 0:09:05.\n",
      "  Batch 1,120  of  4,191.    Elapsed: 0:09:26.\n",
      "  Batch 1,160  of  4,191.    Elapsed: 0:09:46.\n",
      "  Batch 1,200  of  4,191.    Elapsed: 0:10:06.\n",
      "  Batch 1,240  of  4,191.    Elapsed: 0:10:26.\n",
      "  Batch 1,280  of  4,191.    Elapsed: 0:10:46.\n",
      "  Batch 1,320  of  4,191.    Elapsed: 0:11:06.\n",
      "  Batch 1,360  of  4,191.    Elapsed: 0:11:26.\n",
      "  Batch 1,400  of  4,191.    Elapsed: 0:11:46.\n",
      "  Batch 1,440  of  4,191.    Elapsed: 0:12:07.\n",
      "  Batch 1,480  of  4,191.    Elapsed: 0:12:27.\n",
      "  Batch 1,520  of  4,191.    Elapsed: 0:12:47.\n",
      "  Batch 1,560  of  4,191.    Elapsed: 0:13:07.\n",
      "  Batch 1,600  of  4,191.    Elapsed: 0:13:27.\n",
      "  Batch 1,640  of  4,191.    Elapsed: 0:13:47.\n",
      "  Batch 1,680  of  4,191.    Elapsed: 0:14:07.\n",
      "  Batch 1,720  of  4,191.    Elapsed: 0:14:27.\n",
      "  Batch 1,760  of  4,191.    Elapsed: 0:14:48.\n",
      "  Batch 1,800  of  4,191.    Elapsed: 0:15:08.\n",
      "  Batch 1,840  of  4,191.    Elapsed: 0:15:28.\n",
      "  Batch 1,880  of  4,191.    Elapsed: 0:15:48.\n",
      "  Batch 1,920  of  4,191.    Elapsed: 0:16:08.\n",
      "  Batch 1,960  of  4,191.    Elapsed: 0:16:28.\n",
      "  Batch 2,000  of  4,191.    Elapsed: 0:16:48.\n",
      "  Batch 2,040  of  4,191.    Elapsed: 0:17:08.\n",
      "  Batch 2,080  of  4,191.    Elapsed: 0:17:29.\n",
      "  Batch 2,120  of  4,191.    Elapsed: 0:17:49.\n",
      "  Batch 2,160  of  4,191.    Elapsed: 0:18:09.\n",
      "  Batch 2,200  of  4,191.    Elapsed: 0:18:29.\n",
      "  Batch 2,240  of  4,191.    Elapsed: 0:18:49.\n",
      "  Batch 2,280  of  4,191.    Elapsed: 0:19:09.\n",
      "  Batch 2,320  of  4,191.    Elapsed: 0:19:29.\n",
      "  Batch 2,360  of  4,191.    Elapsed: 0:19:50.\n",
      "  Batch 2,400  of  4,191.    Elapsed: 0:20:10.\n",
      "  Batch 2,440  of  4,191.    Elapsed: 0:20:30.\n",
      "  Batch 2,480  of  4,191.    Elapsed: 0:20:50.\n",
      "  Batch 2,520  of  4,191.    Elapsed: 0:21:10.\n",
      "  Batch 2,560  of  4,191.    Elapsed: 0:21:30.\n",
      "  Batch 2,600  of  4,191.    Elapsed: 0:21:50.\n",
      "  Batch 2,640  of  4,191.    Elapsed: 0:22:10.\n",
      "  Batch 2,680  of  4,191.    Elapsed: 0:22:31.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,720  of  4,191.    Elapsed: 0:22:51.\n",
      "  Batch 2,760  of  4,191.    Elapsed: 0:23:11.\n",
      "  Batch 2,800  of  4,191.    Elapsed: 0:23:31.\n",
      "  Batch 2,840  of  4,191.    Elapsed: 0:23:51.\n",
      "  Batch 2,880  of  4,191.    Elapsed: 0:24:11.\n",
      "  Batch 2,920  of  4,191.    Elapsed: 0:24:31.\n",
      "  Batch 2,960  of  4,191.    Elapsed: 0:24:51.\n",
      "  Batch 3,000  of  4,191.    Elapsed: 0:25:12.\n",
      "  Batch 3,040  of  4,191.    Elapsed: 0:25:32.\n",
      "  Batch 3,080  of  4,191.    Elapsed: 0:25:52.\n",
      "  Batch 3,120  of  4,191.    Elapsed: 0:26:12.\n",
      "  Batch 3,160  of  4,191.    Elapsed: 0:26:32.\n",
      "  Batch 3,200  of  4,191.    Elapsed: 0:26:52.\n",
      "  Batch 3,240  of  4,191.    Elapsed: 0:27:12.\n",
      "  Batch 3,280  of  4,191.    Elapsed: 0:27:32.\n",
      "  Batch 3,320  of  4,191.    Elapsed: 0:27:53.\n",
      "  Batch 3,360  of  4,191.    Elapsed: 0:28:13.\n",
      "  Batch 3,400  of  4,191.    Elapsed: 0:28:33.\n",
      "  Batch 3,440  of  4,191.    Elapsed: 0:28:53.\n",
      "  Batch 3,480  of  4,191.    Elapsed: 0:29:14.\n",
      "  Batch 3,520  of  4,191.    Elapsed: 0:29:34.\n",
      "  Batch 3,560  of  4,191.    Elapsed: 0:29:54.\n",
      "  Batch 3,600  of  4,191.    Elapsed: 0:30:14.\n",
      "  Batch 3,640  of  4,191.    Elapsed: 0:30:34.\n",
      "  Batch 3,680  of  4,191.    Elapsed: 0:30:54.\n",
      "  Batch 3,720  of  4,191.    Elapsed: 0:31:14.\n",
      "  Batch 3,760  of  4,191.    Elapsed: 0:31:34.\n",
      "  Batch 3,800  of  4,191.    Elapsed: 0:31:55.\n",
      "  Batch 3,840  of  4,191.    Elapsed: 0:32:15.\n",
      "  Batch 3,880  of  4,191.    Elapsed: 0:32:35.\n",
      "  Batch 3,920  of  4,191.    Elapsed: 0:32:55.\n",
      "  Batch 3,960  of  4,191.    Elapsed: 0:33:15.\n",
      "  Batch 4,000  of  4,191.    Elapsed: 0:33:35.\n",
      "  Batch 4,040  of  4,191.    Elapsed: 0:33:55.\n",
      "  Batch 4,080  of  4,191.    Elapsed: 0:34:15.\n",
      "  Batch 4,120  of  4,191.    Elapsed: 0:34:36.\n",
      "  Batch 4,160  of  4,191.    Elapsed: 0:34:56.\n",
      "\n",
      "  Average training loss: 1.24\n",
      "  Training epoch took: 0:35:11\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.68\n",
      "  Validation took: 0:02:23\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  4,191.    Elapsed: 0:00:20.\n",
      "  Batch    80  of  4,191.    Elapsed: 0:00:40.\n",
      "  Batch   120  of  4,191.    Elapsed: 0:01:00.\n",
      "  Batch   160  of  4,191.    Elapsed: 0:01:21.\n",
      "  Batch   200  of  4,191.    Elapsed: 0:01:41.\n",
      "  Batch   240  of  4,191.    Elapsed: 0:02:01.\n",
      "  Batch   280  of  4,191.    Elapsed: 0:02:21.\n",
      "  Batch   320  of  4,191.    Elapsed: 0:02:41.\n",
      "  Batch   360  of  4,191.    Elapsed: 0:03:01.\n",
      "  Batch   400  of  4,191.    Elapsed: 0:03:21.\n",
      "  Batch   440  of  4,191.    Elapsed: 0:03:41.\n",
      "  Batch   480  of  4,191.    Elapsed: 0:04:02.\n",
      "  Batch   520  of  4,191.    Elapsed: 0:04:22.\n",
      "  Batch   560  of  4,191.    Elapsed: 0:04:42.\n",
      "  Batch   600  of  4,191.    Elapsed: 0:05:02.\n",
      "  Batch   640  of  4,191.    Elapsed: 0:05:22.\n",
      "  Batch   680  of  4,191.    Elapsed: 0:05:42.\n",
      "  Batch   720  of  4,191.    Elapsed: 0:06:02.\n",
      "  Batch   760  of  4,191.    Elapsed: 0:06:22.\n",
      "  Batch   800  of  4,191.    Elapsed: 0:06:43.\n",
      "  Batch   840  of  4,191.    Elapsed: 0:07:03.\n",
      "  Batch   880  of  4,191.    Elapsed: 0:07:23.\n",
      "  Batch   920  of  4,191.    Elapsed: 0:07:43.\n",
      "  Batch   960  of  4,191.    Elapsed: 0:08:03.\n",
      "  Batch 1,000  of  4,191.    Elapsed: 0:08:23.\n",
      "  Batch 1,040  of  4,191.    Elapsed: 0:08:43.\n",
      "  Batch 1,080  of  4,191.    Elapsed: 0:09:03.\n",
      "  Batch 1,120  of  4,191.    Elapsed: 0:09:24.\n",
      "  Batch 1,160  of  4,191.    Elapsed: 0:09:44.\n",
      "  Batch 1,200  of  4,191.    Elapsed: 0:10:04.\n",
      "  Batch 1,240  of  4,191.    Elapsed: 0:10:24.\n",
      "  Batch 1,280  of  4,191.    Elapsed: 0:10:44.\n",
      "  Batch 1,320  of  4,191.    Elapsed: 0:11:04.\n",
      "  Batch 1,360  of  4,191.    Elapsed: 0:11:24.\n",
      "  Batch 1,400  of  4,191.    Elapsed: 0:11:45.\n",
      "  Batch 1,440  of  4,191.    Elapsed: 0:12:05.\n",
      "  Batch 1,480  of  4,191.    Elapsed: 0:12:25.\n",
      "  Batch 1,520  of  4,191.    Elapsed: 0:12:45.\n",
      "  Batch 1,560  of  4,191.    Elapsed: 0:13:05.\n",
      "  Batch 1,600  of  4,191.    Elapsed: 0:13:25.\n",
      "  Batch 1,640  of  4,191.    Elapsed: 0:13:45.\n",
      "  Batch 1,680  of  4,191.    Elapsed: 0:14:05.\n",
      "  Batch 1,720  of  4,191.    Elapsed: 0:14:26.\n",
      "  Batch 1,760  of  4,191.    Elapsed: 0:14:46.\n",
      "  Batch 1,800  of  4,191.    Elapsed: 0:15:06.\n",
      "  Batch 1,840  of  4,191.    Elapsed: 0:15:26.\n",
      "  Batch 1,880  of  4,191.    Elapsed: 0:15:46.\n",
      "  Batch 1,920  of  4,191.    Elapsed: 0:16:06.\n",
      "  Batch 1,960  of  4,191.    Elapsed: 0:16:26.\n",
      "  Batch 2,000  of  4,191.    Elapsed: 0:16:46.\n",
      "  Batch 2,040  of  4,191.    Elapsed: 0:17:07.\n",
      "  Batch 2,080  of  4,191.    Elapsed: 0:17:27.\n",
      "  Batch 2,120  of  4,191.    Elapsed: 0:17:47.\n",
      "  Batch 2,160  of  4,191.    Elapsed: 0:18:07.\n",
      "  Batch 2,200  of  4,191.    Elapsed: 0:18:27.\n",
      "  Batch 2,240  of  4,191.    Elapsed: 0:18:47.\n",
      "  Batch 2,280  of  4,191.    Elapsed: 0:19:07.\n",
      "  Batch 2,320  of  4,191.    Elapsed: 0:19:27.\n",
      "  Batch 2,360  of  4,191.    Elapsed: 0:19:48.\n",
      "  Batch 2,400  of  4,191.    Elapsed: 0:20:08.\n",
      "  Batch 2,440  of  4,191.    Elapsed: 0:20:28.\n",
      "  Batch 2,480  of  4,191.    Elapsed: 0:20:48.\n",
      "  Batch 2,520  of  4,191.    Elapsed: 0:21:08.\n",
      "  Batch 2,560  of  4,191.    Elapsed: 0:21:28.\n",
      "  Batch 2,600  of  4,191.    Elapsed: 0:21:48.\n",
      "  Batch 2,640  of  4,191.    Elapsed: 0:22:09.\n",
      "  Batch 2,680  of  4,191.    Elapsed: 0:22:29.\n",
      "  Batch 2,720  of  4,191.    Elapsed: 0:22:49.\n",
      "  Batch 2,760  of  4,191.    Elapsed: 0:23:09.\n",
      "  Batch 2,800  of  4,191.    Elapsed: 0:23:29.\n",
      "  Batch 2,840  of  4,191.    Elapsed: 0:23:49.\n",
      "  Batch 2,880  of  4,191.    Elapsed: 0:24:09.\n",
      "  Batch 2,920  of  4,191.    Elapsed: 0:24:29.\n",
      "  Batch 2,960  of  4,191.    Elapsed: 0:24:50.\n",
      "  Batch 3,000  of  4,191.    Elapsed: 0:25:10.\n",
      "  Batch 3,040  of  4,191.    Elapsed: 0:25:30.\n",
      "  Batch 3,080  of  4,191.    Elapsed: 0:25:50.\n",
      "  Batch 3,120  of  4,191.    Elapsed: 0:26:10.\n",
      "  Batch 3,160  of  4,191.    Elapsed: 0:26:30.\n",
      "  Batch 3,200  of  4,191.    Elapsed: 0:26:50.\n",
      "  Batch 3,240  of  4,191.    Elapsed: 0:27:10.\n",
      "  Batch 3,280  of  4,191.    Elapsed: 0:27:31.\n",
      "  Batch 3,320  of  4,191.    Elapsed: 0:27:51.\n",
      "  Batch 3,360  of  4,191.    Elapsed: 0:28:11.\n",
      "  Batch 3,400  of  4,191.    Elapsed: 0:28:31.\n",
      "  Batch 3,440  of  4,191.    Elapsed: 0:28:51.\n",
      "  Batch 3,480  of  4,191.    Elapsed: 0:29:11.\n",
      "  Batch 3,520  of  4,191.    Elapsed: 0:29:31.\n",
      "  Batch 3,560  of  4,191.    Elapsed: 0:29:51.\n",
      "  Batch 3,600  of  4,191.    Elapsed: 0:30:12.\n",
      "  Batch 3,640  of  4,191.    Elapsed: 0:30:32.\n",
      "  Batch 3,680  of  4,191.    Elapsed: 0:30:52.\n",
      "  Batch 3,720  of  4,191.    Elapsed: 0:31:12.\n",
      "  Batch 3,760  of  4,191.    Elapsed: 0:31:32.\n",
      "  Batch 3,800  of  4,191.    Elapsed: 0:31:52.\n",
      "  Batch 3,840  of  4,191.    Elapsed: 0:32:12.\n",
      "  Batch 3,880  of  4,191.    Elapsed: 0:32:32.\n",
      "  Batch 3,920  of  4,191.    Elapsed: 0:32:53.\n",
      "  Batch 3,960  of  4,191.    Elapsed: 0:33:13.\n",
      "  Batch 4,000  of  4,191.    Elapsed: 0:33:33.\n",
      "  Batch 4,040  of  4,191.    Elapsed: 0:33:53.\n",
      "  Batch 4,080  of  4,191.    Elapsed: 0:34:13.\n",
      "  Batch 4,120  of  4,191.    Elapsed: 0:34:33.\n",
      "  Batch 4,160  of  4,191.    Elapsed: 0:34:53.\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epoch took: 0:35:09\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.71\n",
      "  Validation took: 0:02:23\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  4,191.    Elapsed: 0:00:20.\n",
      "  Batch    80  of  4,191.    Elapsed: 0:00:40.\n",
      "  Batch   120  of  4,191.    Elapsed: 0:01:00.\n",
      "  Batch   160  of  4,191.    Elapsed: 0:01:20.\n",
      "  Batch   200  of  4,191.    Elapsed: 0:01:41.\n",
      "  Batch   240  of  4,191.    Elapsed: 0:02:01.\n",
      "  Batch   280  of  4,191.    Elapsed: 0:02:21.\n",
      "  Batch   320  of  4,191.    Elapsed: 0:02:41.\n",
      "  Batch   360  of  4,191.    Elapsed: 0:03:01.\n",
      "  Batch   400  of  4,191.    Elapsed: 0:03:21.\n",
      "  Batch   440  of  4,191.    Elapsed: 0:03:41.\n",
      "  Batch   480  of  4,191.    Elapsed: 0:04:01.\n",
      "  Batch   520  of  4,191.    Elapsed: 0:04:22.\n",
      "  Batch   560  of  4,191.    Elapsed: 0:04:42.\n",
      "  Batch   600  of  4,191.    Elapsed: 0:05:02.\n",
      "  Batch   640  of  4,191.    Elapsed: 0:05:22.\n",
      "  Batch   680  of  4,191.    Elapsed: 0:05:42.\n",
      "  Batch   720  of  4,191.    Elapsed: 0:06:02.\n",
      "  Batch   760  of  4,191.    Elapsed: 0:06:22.\n",
      "  Batch   800  of  4,191.    Elapsed: 0:06:43.\n",
      "  Batch   840  of  4,191.    Elapsed: 0:07:03.\n",
      "  Batch   880  of  4,191.    Elapsed: 0:07:23.\n",
      "  Batch   920  of  4,191.    Elapsed: 0:07:43.\n",
      "  Batch   960  of  4,191.    Elapsed: 0:08:03.\n",
      "  Batch 1,000  of  4,191.    Elapsed: 0:08:23.\n",
      "  Batch 1,040  of  4,191.    Elapsed: 0:08:43.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,080  of  4,191.    Elapsed: 0:09:03.\n",
      "  Batch 1,120  of  4,191.    Elapsed: 0:09:24.\n",
      "  Batch 1,160  of  4,191.    Elapsed: 0:09:44.\n",
      "  Batch 1,200  of  4,191.    Elapsed: 0:10:04.\n",
      "  Batch 1,240  of  4,191.    Elapsed: 0:10:24.\n",
      "  Batch 1,280  of  4,191.    Elapsed: 0:10:44.\n",
      "  Batch 1,320  of  4,191.    Elapsed: 0:11:04.\n",
      "  Batch 1,360  of  4,191.    Elapsed: 0:11:24.\n",
      "  Batch 1,400  of  4,191.    Elapsed: 0:11:44.\n",
      "  Batch 1,440  of  4,191.    Elapsed: 0:12:05.\n",
      "  Batch 1,480  of  4,191.    Elapsed: 0:12:25.\n",
      "  Batch 1,520  of  4,191.    Elapsed: 0:12:45.\n",
      "  Batch 1,560  of  4,191.    Elapsed: 0:13:05.\n",
      "  Batch 1,600  of  4,191.    Elapsed: 0:13:25.\n",
      "  Batch 1,640  of  4,191.    Elapsed: 0:13:45.\n",
      "  Batch 1,680  of  4,191.    Elapsed: 0:14:05.\n",
      "  Batch 1,720  of  4,191.    Elapsed: 0:14:25.\n",
      "  Batch 1,760  of  4,191.    Elapsed: 0:14:46.\n",
      "  Batch 1,800  of  4,191.    Elapsed: 0:15:06.\n",
      "  Batch 1,840  of  4,191.    Elapsed: 0:15:26.\n",
      "  Batch 1,880  of  4,191.    Elapsed: 0:15:46.\n",
      "  Batch 1,920  of  4,191.    Elapsed: 0:16:06.\n",
      "  Batch 1,960  of  4,191.    Elapsed: 0:16:26.\n",
      "  Batch 2,000  of  4,191.    Elapsed: 0:16:46.\n",
      "  Batch 2,040  of  4,191.    Elapsed: 0:17:07.\n",
      "  Batch 2,080  of  4,191.    Elapsed: 0:17:27.\n",
      "  Batch 2,120  of  4,191.    Elapsed: 0:17:47.\n",
      "  Batch 2,160  of  4,191.    Elapsed: 0:18:07.\n",
      "  Batch 2,200  of  4,191.    Elapsed: 0:18:27.\n",
      "  Batch 2,240  of  4,191.    Elapsed: 0:18:47.\n",
      "  Batch 2,280  of  4,191.    Elapsed: 0:19:07.\n",
      "  Batch 2,320  of  4,191.    Elapsed: 0:19:27.\n",
      "  Batch 2,360  of  4,191.    Elapsed: 0:19:48.\n",
      "  Batch 2,400  of  4,191.    Elapsed: 0:20:08.\n",
      "  Batch 2,440  of  4,191.    Elapsed: 0:20:28.\n",
      "  Batch 2,480  of  4,191.    Elapsed: 0:20:48.\n",
      "  Batch 2,520  of  4,191.    Elapsed: 0:21:08.\n",
      "  Batch 2,560  of  4,191.    Elapsed: 0:21:28.\n",
      "  Batch 2,600  of  4,191.    Elapsed: 0:21:48.\n",
      "  Batch 2,640  of  4,191.    Elapsed: 0:22:08.\n",
      "  Batch 2,680  of  4,191.    Elapsed: 0:22:29.\n",
      "  Batch 2,720  of  4,191.    Elapsed: 0:22:49.\n",
      "  Batch 2,760  of  4,191.    Elapsed: 0:23:09.\n",
      "  Batch 2,800  of  4,191.    Elapsed: 0:23:29.\n",
      "  Batch 2,840  of  4,191.    Elapsed: 0:23:49.\n",
      "  Batch 2,880  of  4,191.    Elapsed: 0:24:10.\n",
      "  Batch 2,920  of  4,191.    Elapsed: 0:24:30.\n",
      "  Batch 2,960  of  4,191.    Elapsed: 0:24:50.\n",
      "  Batch 3,000  of  4,191.    Elapsed: 0:25:10.\n",
      "  Batch 3,040  of  4,191.    Elapsed: 0:25:30.\n",
      "  Batch 3,080  of  4,191.    Elapsed: 0:25:51.\n",
      "  Batch 3,120  of  4,191.    Elapsed: 0:26:11.\n",
      "  Batch 3,160  of  4,191.    Elapsed: 0:26:31.\n",
      "  Batch 3,200  of  4,191.    Elapsed: 0:26:51.\n",
      "  Batch 3,240  of  4,191.    Elapsed: 0:27:12.\n",
      "  Batch 3,280  of  4,191.    Elapsed: 0:27:32.\n",
      "  Batch 3,320  of  4,191.    Elapsed: 0:27:52.\n",
      "  Batch 3,360  of  4,191.    Elapsed: 0:28:12.\n",
      "  Batch 3,400  of  4,191.    Elapsed: 0:28:32.\n",
      "  Batch 3,440  of  4,191.    Elapsed: 0:28:53.\n",
      "  Batch 3,480  of  4,191.    Elapsed: 0:29:13.\n",
      "  Batch 3,520  of  4,191.    Elapsed: 0:29:33.\n",
      "  Batch 3,560  of  4,191.    Elapsed: 0:29:53.\n",
      "  Batch 3,600  of  4,191.    Elapsed: 0:30:13.\n",
      "  Batch 3,640  of  4,191.    Elapsed: 0:30:33.\n",
      "  Batch 3,680  of  4,191.    Elapsed: 0:30:53.\n",
      "  Batch 3,720  of  4,191.    Elapsed: 0:31:13.\n",
      "  Batch 3,760  of  4,191.    Elapsed: 0:31:34.\n",
      "  Batch 3,800  of  4,191.    Elapsed: 0:31:54.\n",
      "  Batch 3,840  of  4,191.    Elapsed: 0:32:14.\n",
      "  Batch 3,880  of  4,191.    Elapsed: 0:32:34.\n",
      "  Batch 3,920  of  4,191.    Elapsed: 0:32:54.\n",
      "  Batch 3,960  of  4,191.    Elapsed: 0:33:14.\n",
      "  Batch 4,000  of  4,191.    Elapsed: 0:33:34.\n",
      "  Batch 4,040  of  4,191.    Elapsed: 0:33:54.\n",
      "  Batch 4,080  of  4,191.    Elapsed: 0:34:15.\n",
      "  Batch 4,120  of  4,191.    Elapsed: 0:34:35.\n",
      "  Batch 4,160  of  4,191.    Elapsed: 0:34:55.\n",
      "\n",
      "  Average training loss: 0.92\n",
      "  Training epoch took: 0:35:10\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.72\n",
      "  Validation took: 0:02:23\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = random.getrandbits(32) #42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "for epoch_i in range(0, EPOCHS):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, EPOCHS))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_loss = 0 # Reset the total loss for this epoch.\n",
    "    model.train() # Just sets the `mode`, does not perform training\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad() # Always clear any previously calculated gradients before performing a backward pass. Not automatic with PyTorch\n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        loss = outputs[0] # Pull loss value out of the tuple\n",
    "\n",
    "        total_loss += loss.item() # For average loss calculation at the end\n",
    "\n",
    "        \n",
    "        loss.backward() # Perform a backward pass to calculate the gradients.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Prevent exploding gradients\n",
    "\n",
    "        optimizer.step() # Take a step with the new gradients\n",
    "\n",
    "        scheduler.step() # Update the learning rate\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader) # Calculate the average loss over the training data.         \n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    model.eval() # Evaluation mode. Dropout layers behave differently\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids) # Calculate the accuracy for this batch of test sentences.\n",
    "        \n",
    "        eval_accuracy += tmp_eval_accuracy  # Accumulate the total accuracy.\n",
    "        nb_eval_steps += 1 # Track the number of batches\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5NuBjMLimIxp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ../Models/ModelV2/Model_ExtraVocab/Phrases_Only/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../Models/ModelV2/Model_ExtraVocab/Phrases_Only/vocab.txt',\n",
       " '../Models/ModelV2/Model_ExtraVocab/Phrases_Only/special_tokens_map.json',\n",
       " '../Models/ModelV2/Model_ExtraVocab/Phrases_Only/added_tokens.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = '../Models/ModelV2/Model_ExtraVocab/Phrases_Only/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdbmuiAZmVRC"
   },
   "outputs": [],
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E9beXwZgoEre"
   },
   "outputs": [],
   "source": [
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2jVJsJEgrwBy"
   },
   "outputs": [],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(test_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in test_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_values = [prediction.argmax() for prediction in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_values, true_values = [], []\n",
    "for batch in predictions:\n",
    "    for prediction in batch:\n",
    "        prediction_values.append(prediction.argmax())\n",
    "\n",
    "for batch in true_labels:\n",
    "    for true_value in batch:\n",
    "        true_values.append(true_value)\n",
    "\n",
    "count = 0\n",
    "for prediction, true_label in zip(prediction_values, true_values):\n",
    "    if prediction == true_label:\n",
    "        count+=1\n",
    "        \n",
    "# Base model Predicted 10388 / 14367 0.7230458690053595 correctly\n",
    "print(\"Predicted {} / {} {} correctly\".format(count, len(prediction_values), float(count) / float(len(prediction_values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Credentials Management Errors'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwe_lookup_table = pd.read_csv(\"../datasets/cwe-lookup-table.csv\",index_col=False)\n",
    "\n",
    "cwe_lookup_table.loc[cwe_lookup_table['CWE-ID'] == 255][\"Description\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, sentence, lookup_table):\n",
    "  # Drop into evaluation mode\n",
    "  model.eval()\n",
    "\n",
    "  # Send model to the CPU\n",
    "  model.cpu()\n",
    "\n",
    "  # Tokenize the provided text\n",
    "  # TODO: Tokenizer global at the moment, change that\n",
    "  encoded_sent = tokenizer.encode(sentence, add_special_tokens=True, max_length=MAX_LEN, pad_to_max_length=True)\n",
    "  attention_mask = [int(token_id > 0) for token_id in encoded_sent]\n",
    "\n",
    "  # 1x512 tensor\n",
    "  sent_tensor = torch.tensor([encoded_sent])\n",
    "  attn_tensor = torch.tensor([attention_mask])\n",
    "\n",
    "  # Speeds up calc when gradients don't need to be calculated\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      # TODO: Why no softmax output??\n",
    "      outputs = model(sent_tensor, token_type_ids=None, \n",
    "                      attention_mask=attn_tensor)\n",
    "      logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  #print(logits)\n",
    "  prediction = logits.argmax()\n",
    "  # `lookup_table` holds mapping of labels to CWEs.\n",
    "  # TODO: Save the lookup table alongside model weights\n",
    "  for k,v in lookup_table.items():\n",
    "    if v == prediction:\n",
    "      cwe = k\n",
    "      break\n",
    "  try:\n",
    "    # Not all CWEs present in the lookup table (mainly 'CWE CATEGORIES' which are missing)\n",
    "    # TODO: Extract CWEs for master XML spec, not CSVs - DONE\n",
    "    # TODO: Generate additional training data from CWE spec. At least 3 cases for each CWE can be created with 'Description',\n",
    "    #         'Extended Description', and 'Background Detail', possibly more - DONE\n",
    "    # \n",
    "    description = cwe_lookup_table.loc[cwe_lookup_table['CWE-ID'] == cwe][\"Description\"].values[0]\n",
    "  except:\n",
    "    description = \"💩\"\n",
    "\n",
    "  print(\"Input: {}\\n\\tPredicted CWE: {}: {}, Prob: {}\".format(sentence, cwe, description, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: The app accepts a user controlled serialized object\n",
      "\tPredicted CWE: 502: Deserialization of Untrusted Data, Prob: 244\n",
      "Input: Site deserializes client side object\n",
      "\tPredicted CWE: 502: Deserialization of Untrusted Data, Prob: 244\n",
      "Input: There is no database parameterization\n",
      "\tPredicted CWE: 200: Exposure of Sensitive Information to an Unauthorized Actor, Prob: 99\n",
      "Input: There is insufficient validation of the 'id' parameter when used with SQL statement\n",
      "\tPredicted CWE: 89: Improper Neutralization of Special Elements used in an SQL Command ('SQL Injection'), Prob: 43\n",
      "Input: One user can access another's messages\n",
      "\tPredicted CWE: 532: Insertion of Sensitive Information into Log File, Prob: 247\n",
      "Input: An attacker can spoof someone else's access token. Ruh roh. \n",
      "\tPredicted CWE: 451: User Interface (UI) Misrepresentation of Critical Information, Prob: 231\n",
      "Input: There's no bounds checking on the input buffer\n",
      "\tPredicted CWE: 119: Improper Restriction of Operations within the Bounds of a Memory Buffer, Prob: 56\n",
      "Input: Passwords are stored clear text\n",
      "\tPredicted CWE: 522: Insufficiently Protected Credentials, Prob: 246\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"The app accepts a user controlled serialized object\", lookup_table)\n",
    "predict(model, \"Site deserializes client side object\", lookup_table)\n",
    "predict(model, \"There is no database parameterization\", lookup_table)\n",
    "predict(model, \"There is insufficient validation of the 'id' parameter when used with SQL statement\", lookup_table)\n",
    "predict(model, \"One user can access another's messages\", lookup_table)\n",
    "predict(model, \"An attacker can spoof someone else's access token. Ruh roh. \", lookup_table)\n",
    "predict(model, \"There's no bounds checking on the input buffer\", lookup_table)\n",
    "predict(model, \"Passwords are stored clear text\", lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ip whitelisting is not in place\n",
      "\tPredicted CWE: 269: Improper Privilege Management, Prob: 128\n",
      "Input: No https\n",
      "\tPredicted CWE: 254: 7PK - Security Features, Prob: 121\n",
      "Input: No tls\n",
      "\tPredicted CWE: 611: Improper Restriction of XML External Entity Reference, Prob: 257\n",
      "Input: no hardware R/X protections\n",
      "\tPredicted CWE: 862: Missing Authorization, Prob: 345\n",
      "Input: httponly flag isnt set\n",
      "\tPredicted CWE: 352: Cross-Site Request Forgery (CSRF), Prob: 183\n",
      "Input: There is no ASLR IN PLACE\n",
      "\tPredicted CWE: 362: Concurrent Execution using Shared Resource with Improper Synchronization ('Race Condition'), Prob: 189\n",
      "Input: site is getting DDoSd\n",
      "\tPredicted CWE: 190: Integer Overflow or Wraparound, Prob: 92\n"
     ]
    }
   ],
   "source": [
    "# Model fails hard\n",
    "predict(model, \"ip whitelisting is not in place\", lookup_table)\n",
    "predict(model, \"No https\", lookup_table)\n",
    "predict(model, \"No tls\", lookup_table)\n",
    "predict(model, \"no hardware R/X protections\", lookup_table)\n",
    "predict(model, \"httponly flag isnt set\", lookup_table)\n",
    "predict(model, \"There is no ASLR IN PLACE\", lookup_table)\n",
    "predict(model, \"site is getting DDoSd\", lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ../\n",
      "\tPredicted CWE: 23: Relative Path Traversal, Prob: 6\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"../\", lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Router admin interface has default credentials\n",
      "\tPredicted CWE: 798: Use of Hard-coded Credentials, Prob: 322\n",
      "Input: Our stored passwords will live for all eternity\n",
      "\tPredicted CWE: 522: Insufficiently Protected Credentials, Prob: 246\n",
      "Input: full disk encryption is not present\n",
      "\tPredicted CWE: 326: Inadequate Encryption Strength, Prob: 168\n",
      "Input: seed is not random\n",
      "\tPredicted CWE: 330: Use of Insufficiently Random Values, Prob: 170\n",
      "Input: Credentials are just flying around unencrypted\n",
      "\tPredicted CWE: 522: Insufficiently Protected Credentials, Prob: 246\n",
      "Input: Credentials are just flying?\n",
      "\tPredicted CWE: 522: Insufficiently Protected Credentials, Prob: 246\n",
      "Input: passwords are just flying around unencrypted\n",
      "\tPredicted CWE: 311: Missing Encryption of Sensitive Data, Prob: 159\n",
      "\n",
      "Semantics\n",
      "Input: personal info exposed by misconfigured S3 bucket\n",
      "\tPredicted CWE: 200: Exposure of Sensitive Information to an Unauthorized Actor, Prob: 99\n",
      "Input: info (PII) leaked through improperly configured object storage\n",
      "\tPredicted CWE: 200: Exposure of Sensitive Information to an Unauthorized Actor, Prob: 99\n",
      "Input: bad guy stole stuff\n",
      "\tPredicted CWE: 732: Incorrect Permission Assignment for Critical Resource, Prob: 300\n",
      "Input: data breach of user personal data\n",
      "\tPredicted CWE: 532: Insertion of Sensitive Information into Log File, Prob: 247\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"Router admin interface has default credentials\", lookup_table)\n",
    "predict(model, \"Our stored passwords will live for all eternity\", lookup_table)\n",
    "predict(model, \"full disk encryption is not present\", lookup_table)\n",
    "predict(model, \"seed is not random\", lookup_table)\n",
    "predict(model, \"Credentials are just flying around unencrypted\", lookup_table)\n",
    "predict(model, \"Credentials are just flying?\", lookup_table)\n",
    "predict(model, \"passwords are just flying around unencrypted\", lookup_table)\n",
    "\n",
    "\n",
    "\n",
    "# Illustrate semantic variety\n",
    "print(\"\\nSemantics\")\n",
    "predict(model, \"personal info exposed by misconfigured S3 bucket\", lookup_table)\n",
    "predict(model, \"info (PII) leaked through improperly configured object storage\", lookup_table)\n",
    "predict(model, \"bad guy stole stuff\", lookup_table)\n",
    "predict(model, \"data breach of user personal data\", lookup_table) # Maps incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: SSRF in Sofort's merchant portal, via notification webhook\n",
      "\tPredicted CWE: 918: Server-Side Request Forgery (SSRF), Prob: 354\n",
      "Input: IDOR in POST /api/settings/PN01964/authentication-email/596/generate-token Allows Attacker to Generate Support Tokens for Other Accounts, Expose Email\n",
      "\tPredicted CWE: 200: Exposure of Sensitive Information to an Unauthorized Actor, Prob: 99\n",
      "Input: [MyDevelopment] XXE processing in SCORM files\n",
      "\tPredicted CWE: 611: Improper Restriction of XML External Entity Reference, Prob: 257\n",
      "Input: Reflected XSS vulnerability on www.sofort.com, via multipay/wait\n",
      "\tPredicted CWE: 79: Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting'), Prob: 35\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"SSRF in Sofort's merchant portal, via notification webhook\", lookup_table)\n",
    "predict(model, \"IDOR in POST /api/settings/PN01964/authentication-email/596/generate-token Allows Attacker to Generate Support Tokens for Other Accounts, Expose Email\", lookup_table)\n",
    "predict(model, \"[MyDevelopment] XXE processing in SCORM files\", lookup_table)\n",
    "predict(model, \"Reflected XSS vulnerability on www.sofort.com, via multipay/wait\", lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: an attacker can execute remote shell commands\n",
      "\tPredicted CWE: 78: Improper Neutralization of Special Elements used in an OS Command ('OS Command Injection'), Prob: 34\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"an attacker can execute remote shell commands\", lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: AWS Metadata is exposed\n",
      "\tPredicted CWE: 200: Exposure of Sensitive Information to an Unauthorized Actor, Prob: 99\n",
      "Input: User supplied request sent to arbitrary destination\n",
      "\tPredicted CWE: 41: Improper Resolution of Path Equivalence, Prob: 16\n",
      "Input: JWT is not verified\n",
      "\tPredicted CWE: 295: Improper Certificate Validation, Prob: 147\n",
      "Input: CBC mode ciphers are enabled\n",
      "\tPredicted CWE: 330: Use of Insufficiently Random Values, Prob: 170\n",
      "Input: MD5 is used to hash passwords\n",
      "\tPredicted CWE: 311: Missing Encryption of Sensitive Data, Prob: 159\n",
      "Input: Insecure initialization vector usage\n",
      "\tPredicted CWE: 400: Uncontrolled Resource Consumption, Prob: 202\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"AWS Metadata is exposed\", lookup_table)\n",
    "predict(model, \"User supplied request sent to arbitrary destination\", lookup_table)\n",
    "predict(model, \"JWT is not verified\", lookup_table)\n",
    "predict(model, \"CBC mode ciphers are enabled\", lookup_table)\n",
    "predict(model, \"MD5 is used to hash passwords\", lookup_table)\n",
    "predict(model, \"Insecure initialization vector usage\", lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67056\n"
     ]
    }
   ],
   "source": [
    "print(4191*16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Model-V2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03ea662ba605432a92dc26d0a28ff1ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57da120472f3496e89904cb1a01da3e4",
      "placeholder": "​",
      "style": "IPY_MODEL_97950f4dcab84e00b5d7c86ed55175fe",
      "value": "100% 361/361 [00:00&lt;00:00, 13.4kB/s]"
     }
    },
    "105715a634d94e45b41960c494a330b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_210d481d407642bea4bb15ca693f4780",
       "IPY_MODEL_bd11b11a7b56476e8a4dbf462ecb4b8d"
      ],
      "layout": "IPY_MODEL_ad9cc6363b534e31a46dff19fe865fae"
     }
    },
    "210d481d407642bea4bb15ca693f4780": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5ad8695c94d4f08b7f190bf7c6d2385",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8c3bfc17779b491aa624c9a46d4d8c4e",
      "value": 440473133
     }
    },
    "3344529ff90f4266af2aaf0c5566c0dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52607b7d432648a9b688cfce5059bf0e",
      "placeholder": "​",
      "style": "IPY_MODEL_d1c5232757d54bcb9cd347d8fc53b857",
      "value": "100% 232k/232k [00:00&lt;00:00, 356kB/s]"
     }
    },
    "3bc72c0f4bc24ebb8c1f78b98e4e229a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3eaba4150a884a9faf441d94eb3cb30e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4017e4f4d45a4b319f731e9db1c24b7e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5243245110c342a0a118aa8a3a596d9a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52607b7d432648a9b688cfce5059bf0e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55bc28d75021466d9e71aada1854668f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac4a4698a28c4be7976deb72bd505af8",
      "max": 361,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3eaba4150a884a9faf441d94eb3cb30e",
      "value": 361
     }
    },
    "57da120472f3496e89904cb1a01da3e4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f8ae24b584f42eba9590e163a92d13d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b737b456003540bfbfe10b6c465ec22e",
       "IPY_MODEL_3344529ff90f4266af2aaf0c5566c0dd"
      ],
      "layout": "IPY_MODEL_5243245110c342a0a118aa8a3a596d9a"
     }
    },
    "646ffdb86a37478c92c20e5401ccec46": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "89421b3102464922837c72b24cb2a440": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c3bfc17779b491aa624c9a46d4d8c4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "96f287cd332d437999a35f0acecbb815": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_55bc28d75021466d9e71aada1854668f",
       "IPY_MODEL_03ea662ba605432a92dc26d0a28ff1ab"
      ],
      "layout": "IPY_MODEL_89421b3102464922837c72b24cb2a440"
     }
    },
    "97950f4dcab84e00b5d7c86ed55175fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5ad8695c94d4f08b7f190bf7c6d2385": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac4a4698a28c4be7976deb72bd505af8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad9cc6363b534e31a46dff19fe865fae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b737b456003540bfbfe10b6c465ec22e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4017e4f4d45a4b319f731e9db1c24b7e",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_646ffdb86a37478c92c20e5401ccec46",
      "value": 231508
     }
    },
    "bd11b11a7b56476e8a4dbf462ecb4b8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc862b9e9f3d4c53a7e3357b0527b113",
      "placeholder": "​",
      "style": "IPY_MODEL_3bc72c0f4bc24ebb8c1f78b98e4e229a",
      "value": "100% 440M/440M [00:44&lt;00:00, 9.84MB/s]"
     }
    },
    "d1c5232757d54bcb9cd347d8fc53b857": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc862b9e9f3d4c53a7e3357b0527b113": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
